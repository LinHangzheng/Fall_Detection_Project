{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Nov  9 15:55:30 2019\n",
    "@author: Shiru, Aviral\n",
    "\"\"\"\n",
    "\n",
    "# resize to 224 X 224 then 3 channel RGB\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "#import scipy.misc\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageReader(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.images = os.listdir(path)\n",
    "        self.images.sort()\n",
    "        self.i = 0\n",
    "    \n",
    "    def read(self):\n",
    "        if self.i >= len(self.images):\n",
    "            return False    , None\n",
    "        self.i = self.i + 1\n",
    "        print(self.images[self.i - 1])\n",
    "        return True, cv2.imread(os.path.join(self.path, self.images[self.i - 1]))\n",
    "\n",
    "    def release(self):\n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'E:/JuniorYearSpring/ECE397/fall_detection/OWN_vidoes'\n",
    "files = os.listdir(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prvs shape: (224, 224)\n",
      "0 (224, 224, 2)\n",
      "1 (224, 224, 2)\n",
      "2 (224, 224, 2)\n",
      "3 (224, 224, 2)\n",
      "4 (224, 224, 2)\n",
      "5 (224, 224, 2)\n",
      "6 (224, 224, 2)\n",
      "7 (224, 224, 2)\n",
      "8 (224, 224, 2)\n",
      "9 (224, 224, 2)\n",
      "10 (224, 224, 2)\n",
      "11 (224, 224, 2)\n",
      "12 (224, 224, 2)\n",
      "13 (224, 224, 2)\n",
      "14 (224, 224, 2)\n",
      "15 (224, 224, 2)\n",
      "16 (224, 224, 2)\n",
      "17 (224, 224, 2)\n",
      "18 (224, 224, 2)\n",
      "19 (224, 224, 2)\n",
      "20 (224, 224, 2)\n",
      "21 (224, 224, 2)\n",
      "22 (224, 224, 2)\n",
      "23 (224, 224, 2)\n",
      "24 (224, 224, 2)\n",
      "25 (224, 224, 2)\n",
      "26 (224, 224, 2)\n",
      "27 (224, 224, 2)\n",
      "28 (224, 224, 2)\n",
      "29 (224, 224, 2)\n",
      "30 (224, 224, 2)\n",
      "31 (224, 224, 2)\n",
      "32 (224, 224, 2)\n",
      "33 (224, 224, 2)\n",
      "34 (224, 224, 2)\n",
      "35 (224, 224, 2)\n",
      "36 (224, 224, 2)\n",
      "37 (224, 224, 2)\n",
      "38 (224, 224, 2)\n",
      "39 (224, 224, 2)\n",
      "40 (224, 224, 2)\n",
      "41 (224, 224, 2)\n",
      "42 (224, 224, 2)\n",
      "43 (224, 224, 2)\n",
      "44 (224, 224, 2)\n",
      "45 (224, 224, 2)\n",
      "46 (224, 224, 2)\n",
      "47 (224, 224, 2)\n",
      "48 (224, 224, 2)\n",
      "49 (224, 224, 2)\n",
      "50 (224, 224, 2)\n",
      "51 (224, 224, 2)\n",
      "52 (224, 224, 2)\n",
      "53 (224, 224, 2)\n",
      "54 (224, 224, 2)\n",
      "55 (224, 224, 2)\n",
      "56 (224, 224, 2)\n",
      "57 (224, 224, 2)\n",
      "58 (224, 224, 2)\n",
      "59 (224, 224, 2)\n",
      "60 (224, 224, 2)\n",
      "61 (224, 224, 2)\n",
      "62 (224, 224, 2)\n",
      "63 (224, 224, 2)\n",
      "64 (224, 224, 2)\n",
      "65 (224, 224, 2)\n",
      "66 (224, 224, 2)\n",
      "67 (224, 224, 2)\n",
      "68 (224, 224, 2)\n",
      "69 (224, 224, 2)\n",
      "70 (224, 224, 2)\n",
      "71 (224, 224, 2)\n",
      "72 (224, 224, 2)\n",
      "73 (224, 224, 2)\n",
      "74 (224, 224, 2)\n",
      "75 (224, 224, 2)\n",
      "76 (224, 224, 2)\n",
      "77 (224, 224, 2)\n",
      "78 (224, 224, 2)\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"\"\"Reads from a video stream and converts them to\n",
    "#     optical flow images\"\"\")\n",
    "# parser.add_argument(\"--video\", help=\"Path to where the video is stored\", type=str)\n",
    "# parser.add_argument(\"--images\", help=\"Path to where images are stored (must be able to be sorted)\", type=str)\n",
    "# parser.add_argument(\"--save_x\", help=\"folder where the x-axis files must be saved\", type=str, required=True)\n",
    "# parser.add_argument(\"--save_y\", help=\"folder where the y-axis files must be saved\", type=str, required=True)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "for video in files:\n",
    "    reader = cv2.VideoCapture('E:/JuniorYearSpring/ECE397/fall_detection/OWN_vidoes/'+video)\n",
    "    save_x = 'E:/JuniorYearSpring/ECE397/fall_detection/OWN_opflow/' + video[0:8]\n",
    "    save_y = save_x\n",
    "    \n",
    "    # create the directory for saving\n",
    "    if not os.path.exists(save_x):\n",
    "        os.makedirs(save_x)\n",
    "        \n",
    "    # if args.images is not None:\n",
    "    #     reader = ImageReader(args.images)\n",
    "    # elif args.video is not None:\n",
    "    #     reader = cv2.VideoCapture(args.video)\n",
    "    # else:\n",
    "    #     reader = cv2.VideoCapture(0) # From camera\n",
    "\n",
    "    success, image = reader.read()\n",
    "\n",
    "    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    prvs = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    print(\"prvs shape: \" + str(prvs.shape))\n",
    "    hsv = np.zeros_like(image)\n",
    "    hsv[...,1] = 255\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while success:\n",
    "        success, image = reader.read()\n",
    "        if success:\n",
    "            image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)  \n",
    "\n",
    "            nex = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            optical_flow = cv2.DualTVL1OpticalFlow_create()\n",
    "            flow = optical_flow.calc(prvs, nex, None)\n",
    "            print(str(count) + \" \" + str(flow.shape))\n",
    "\n",
    "            flow[..., 0] = cv2.normalize(flow[..., 0], None, 0, 255, cv2.NORM_MINMAX)\n",
    "            flow[..., 1] = cv2.normalize(flow[..., 1], None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "            imx = Image.fromarray(flow[..., 0])\n",
    "            if imx.mode != \"L\":\n",
    "                imx = imx.convert('L')\n",
    "            imx.save(os.path.join(save_x, \"flow_x_{}.jpg\".format(str(count).zfill(4))))\n",
    "\n",
    "            imy = Image.fromarray(flow[..., 1])\n",
    "            if imy.mode != \"L\":\n",
    "                imy = imy.convert('L')\n",
    "            imy.save(os.path.join(save_y, \"flow_y_{}.jpg\".format(str(count).zfill(4))))\n",
    "\n",
    "            prvs = nex\n",
    "            count += 1\n",
    "\n",
    "            #if count == 50:\n",
    "            #    break\n",
    "\n",
    "            # cv2.imshow('Test', image)    \n",
    "\n",
    "        # if cv2.waitKey(1) == ord('q'):\n",
    "        #    break\n",
    "\n",
    "\n",
    "    reader.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
